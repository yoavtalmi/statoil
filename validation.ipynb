{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "np.random.seed(666)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from subprocess import check_output\n",
    "import utils\n",
    "from utils import keras_baselilne\n",
    "from utils import resnet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "train = pd.read_json(\"/mnt/extDisk/courses/data/statoil/data/train_half/train.json\")\n",
    "valid = pd.read_json(\"/mnt/extDisk/courses/data/statoil/data/train_half/valid.json\")\n",
    "test = pd.read_json(\"/mnt/extDisk/courses/data/statoil/data/train/test.json\")\n",
    "train_final = pd.read_json(\"/mnt/extDisk/courses/data/statoil/data/train_half/train_final.json\")\n",
    "train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "train.inc_angle = train.inc_angle.astype(float).fillna(0.0)\n",
    "valid.inc_angle = valid.inc_angle.replace('na', 0)\n",
    "valid.inc_angle = valid.inc_angle.astype(float).fillna(0.0)\n",
    "train_final.inc_angle = train_final.inc_angle.replace('na', 0)\n",
    "train_final.inc_angle = train_final.inc_angle.astype(float).fillna(0.0)\n",
    "#train_final = train_final[~(train_final.inc_angle=='na')]\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_train = np.array(train.inc_angle)\n",
    "y_train = np.array(train[\"is_iceberg\"])\n",
    "\n",
    "# Valid data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in valid[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in valid[\"band_2\"]])\n",
    "X_valid = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_valid = np.array(valid.inc_angle)\n",
    "y_valid = np.array(valid[\"is_iceberg\"])\n",
    "\n",
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_test = np.array(test.inc_angle)\n",
    "\n",
    "\n",
    "# Train_final data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_final[\"band_1\"]])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_final[\"band_2\"]])\n",
    "X_train_final = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                          , x_band2[:, :, :, np.newaxis]\n",
    "                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "X_angle_train_final = np.array(train_final.inc_angle)\n",
    "y_train_final = np.array(train_final[\"is_iceberg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_angle_train_final)):\n",
    "    if type(X_angle_train_final[i]) != np.float64 and type(X_angle_train_final[i]) != np.float:\n",
    "        X_angle_train_final[i] = round(np.random.normal(39.2037,3.813),3)\n",
    "#np.random.normal(39.2037,3.813,size=61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[obj for obj in X_angle_train_final if type(obj) != np.float64 and type(obj) != float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_1 (InputLayer)                (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 75, 75, 3)    12          X_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 73, 73, 16)   448         batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 73, 73, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 71, 71, 16)   2320        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 71, 71, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 35, 35, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 35, 35, 16)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 16)   64          dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 33, 33, 32)   4640        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 33, 33, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 31, 31, 32)   9248        batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 31, 31, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 15, 15, 32)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 15, 32)   128         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 13, 64)   18496       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 13, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 64)   36928       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 11, 11, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 5, 5, 64)     0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 3, 3, 128)    73856       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 75, 75, 3)    12          X_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 3, 3, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 73, 73, 128)  3584        batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 36, 36, 128)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 1, 128)    0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 36, 36, 128)  0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "angle (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 128)          0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_4 (GlobalM (None, 128)          0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1)            4           angle[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 257)          0           global_max_pooling2d_3[0][0]     \n",
      "                                                                 global_max_pooling2d_4[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          66048       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           16448       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64)           256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            65          dropout_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 234,989\n",
      "Trainable params: 233,535\n",
      "Non-trainable params: 1,454\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "    \n",
    "\n",
    "model = utils.keras_baselilne_batch()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train evaluate:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: na",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8e6bb04a3253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train evaluate:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_angle_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"####################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"watch list evaluate:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1732\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/home/user/tensorflow/local/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: na"
     ]
    }
   ],
   "source": [
    "file_path = \"/mnt/extDisk/courses/data/statoil/data/models/.noise_batch.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "\n",
    "model.load_weights(filepath=file_path)\n",
    "print(\"Train evaluate:\")\n",
    "print(model.evaluate([X_train,X_angle_train], y_train, verbose=1, batch_size=200))\n",
    "print(\"####################\")\n",
    "print(\"watch list evaluate:\")\n",
    "print(model.evaluate([X_train_final,X_angle_train_final], y_train_final, verbose=1, batch_size=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802/802 [==============================] - 0s 174us/step\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model.predict([X_train_final,X_angle_train_final], verbose=1, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>66348d03</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>7052a617</td>\n",
       "      <td>0.407515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>3062fca8</td>\n",
       "      <td>0.998114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>4ea48c18</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>f9209504</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>204afe46</td>\n",
       "      <td>0.697797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>47f0178a</td>\n",
       "      <td>0.943507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>47377a6d</td>\n",
       "      <td>0.877789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>d782d1a6</td>\n",
       "      <td>0.012856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>c04a768c</td>\n",
       "      <td>0.949111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  is_iceberg\n",
       "100   66348d03    0.000797\n",
       "1000  7052a617    0.407515\n",
       "1001  3062fca8    0.998114\n",
       "1002  4ea48c18    0.000884\n",
       "101   f9209504    0.000806\n",
       "1012  204afe46    0.697797\n",
       "1014  47f0178a    0.943507\n",
       "1015  47377a6d    0.877789\n",
       "1016  d782d1a6    0.012856\n",
       "1018  c04a768c    0.949111"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id': train_final[\"id\"], 'is_iceberg': prediction_train.reshape((prediction_train.shape[0]))})\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/mnt/extDisk/courses/data/statoil/data/valid_results/flip_angle.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66348d03</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7052a617</td>\n",
       "      <td>0.074851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3062fca8</td>\n",
       "      <td>0.999131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4ea48c18</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f9209504</td>\n",
       "      <td>0.002119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg\n",
       "0  66348d03    0.000713\n",
       "1  7052a617    0.074851\n",
       "2  3062fca8    0.999131\n",
       "3  4ea48c18    0.000146\n",
       "4  f9209504    0.002119"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_2 = pd.read_csv('/mnt/extDisk/courses/data/statoil/data/valid_results/noise_mix_learning_angle.csv')\n",
    "submission_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission['is_iceberg'] = np.mean([submission['is_iceberg'].values,submission_2['is_iceberg'].values],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22286875489220684"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_train_final,submission['is_iceberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "submissions_dfs = []\n",
    "paths = ['flip_angle.csv', 'ensamble_0211_angle.csv','pseudo_angle.csv', 'black_box_angle.csv','noise_box_angle.csv']\n",
    "#paths = ['data_aug/noise_mix_clean_learning_rate_1.csv','ensamble/stacking_0612.csv']\n",
    "for path in paths:\n",
    "    submission_df = pd.read_csv(\"/mnt/extDisk/courses/data/statoil/data/valid_results/\" + path)\n",
    "    submission_df = submission_df.sort('id')\n",
    "    submissions_dfs.append(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg_0</th>\n",
       "      <th>is_iceberg_1</th>\n",
       "      <th>is_iceberg_2</th>\n",
       "      <th>is_iceberg_3</th>\n",
       "      <th>is_iceberg_4</th>\n",
       "      <th>is_iceberg_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004300e6</td>\n",
       "      <td>0.582211</td>\n",
       "      <td>0.758660</td>\n",
       "      <td>0.587314</td>\n",
       "      <td>0.886724</td>\n",
       "      <td>0.937983</td>\n",
       "      <td>0.847447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00e759b3</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00f3862a</td>\n",
       "      <td>0.804578</td>\n",
       "      <td>0.484320</td>\n",
       "      <td>0.252155</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.779778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00f7ef1c</td>\n",
       "      <td>0.995288</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010355ab</td>\n",
       "      <td>0.583049</td>\n",
       "      <td>0.545799</td>\n",
       "      <td>0.506296</td>\n",
       "      <td>0.487851</td>\n",
       "      <td>0.459540</td>\n",
       "      <td>0.350795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg_0  is_iceberg_1  is_iceberg_2  is_iceberg_3  \\\n",
       "0  004300e6      0.582211      0.758660      0.587314      0.886724   \n",
       "1  00e759b3      0.000149      0.000404      0.001110      0.000030   \n",
       "2  00f3862a      0.804578      0.484320      0.252155      0.963272   \n",
       "3  00f7ef1c      0.995288      0.989437      0.999920      0.999774   \n",
       "4  010355ab      0.583049      0.545799      0.506296      0.487851   \n",
       "\n",
       "   is_iceberg_4  is_iceberg_5  \n",
       "0      0.937983      0.847447  \n",
       "1      0.000625      0.000013  \n",
       "2      0.177252      0.779778  \n",
       "3      0.999383      0.999886  \n",
       "4      0.459540      0.350795  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(submissions_dfs)):\n",
    "    submissions_dfs[i] = submissions_dfs[i].rename(columns={'is_iceberg':'is_iceberg_' +str(i)})\n",
    "\n",
    "concat_sub = submissions_dfs[0]\n",
    "\n",
    "for i in range(1,len(submissions_dfs)):\n",
    "    concat_sub = concat_sub.merge(submissions_dfs[i],on='id')\n",
    "\n",
    "#concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_iceberg_0</th>\n",
       "      <th>is_iceberg_1</th>\n",
       "      <th>is_iceberg_2</th>\n",
       "      <th>is_iceberg_3</th>\n",
       "      <th>is_iceberg_4</th>\n",
       "      <th>is_iceberg_5</th>\n",
       "      <th>is_iceberg_max</th>\n",
       "      <th>is_iceberg_min</th>\n",
       "      <th>is_iceberg_mean</th>\n",
       "      <th>is_iceberg_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004300e6</td>\n",
       "      <td>0.582211</td>\n",
       "      <td>0.758660</td>\n",
       "      <td>0.587314</td>\n",
       "      <td>0.886724</td>\n",
       "      <td>0.937983</td>\n",
       "      <td>0.847447</td>\n",
       "      <td>0.937983</td>\n",
       "      <td>0.582211</td>\n",
       "      <td>0.765067</td>\n",
       "      <td>0.765067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00e759b3</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00f3862a</td>\n",
       "      <td>0.804578</td>\n",
       "      <td>0.484320</td>\n",
       "      <td>0.252155</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.779778</td>\n",
       "      <td>0.963272</td>\n",
       "      <td>0.177252</td>\n",
       "      <td>0.575235</td>\n",
       "      <td>0.575235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00f7ef1c</td>\n",
       "      <td>0.995288</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.999774</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.989437</td>\n",
       "      <td>0.996631</td>\n",
       "      <td>0.999383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010355ab</td>\n",
       "      <td>0.583049</td>\n",
       "      <td>0.545799</td>\n",
       "      <td>0.506296</td>\n",
       "      <td>0.487851</td>\n",
       "      <td>0.459540</td>\n",
       "      <td>0.350795</td>\n",
       "      <td>0.583049</td>\n",
       "      <td>0.350795</td>\n",
       "      <td>0.483397</td>\n",
       "      <td>0.487851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  is_iceberg_0  is_iceberg_1  is_iceberg_2  is_iceberg_3  \\\n",
       "0  004300e6      0.582211      0.758660      0.587314      0.886724   \n",
       "1  00e759b3      0.000149      0.000404      0.001110      0.000030   \n",
       "2  00f3862a      0.804578      0.484320      0.252155      0.963272   \n",
       "3  00f7ef1c      0.995288      0.989437      0.999920      0.999774   \n",
       "4  010355ab      0.583049      0.545799      0.506296      0.487851   \n",
       "\n",
       "   is_iceberg_4  is_iceberg_5  is_iceberg_max  is_iceberg_min  \\\n",
       "0      0.937983      0.847447        0.937983        0.582211   \n",
       "1      0.000625      0.000013        0.001110        0.000013   \n",
       "2      0.177252      0.779778        0.963272        0.177252   \n",
       "3      0.999383      0.999886        0.999920        0.989437   \n",
       "4      0.459540      0.350795        0.583049        0.350795   \n",
       "\n",
       "   is_iceberg_mean  is_iceberg_median  \n",
       "0         0.765067           0.765067  \n",
       "1         0.000432           0.000404  \n",
       "2         0.575235           0.575235  \n",
       "3         0.996631           0.999383  \n",
       "4         0.483397           0.487851  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data fields ready for stacking\n",
    "concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:].max(axis=1)\n",
    "concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:].min(axis=1)\n",
    "concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:].mean(axis=1)\n",
    "concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:].median(axis=1)\n",
    "concat_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.765067\n",
       "1    0.000013\n",
       "2    0.575235\n",
       "3    0.999920\n",
       "4    0.487851\n",
       "Name: is_iceberg, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['is_iceberg_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['is_iceberg_min'], \n",
    "                                             concat_sub['is_iceberg_median']))\n",
    "concat_sub['is_iceberg'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_sub.to_csv('/mnt/extDisk/courses/data/statoil/data/valid_results/stacking_angle.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>[-26.907173, -27.247885, -25.379496, -25.37954...</td>\n",
       "      <td>[-29.186039, -27.972126, -28.358276, -28.76238...</td>\n",
       "      <td>004300e6</td>\n",
       "      <td>42.5591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>[-15.341173, -14.21162, -15.837792, -15.923442...</td>\n",
       "      <td>[-22.030249, -20.892223, -21.046036, -24.18857...</td>\n",
       "      <td>00e759b3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>[-20.174095, -20.66132, -21.917173, -21.917212...</td>\n",
       "      <td>[-27.022549, -25.438961, -21.002024, -21.72630...</td>\n",
       "      <td>00f3862a</td>\n",
       "      <td>45.2814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>[-29.086002, -29.490072, -24.570494, -24.11330...</td>\n",
       "      <td>[-23.67878, -24.338787, -29.490143, -29.490211...</td>\n",
       "      <td>00f7ef1c</td>\n",
       "      <td>34.4748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>[-25.889074, -25.889074, -25.604317, -25.60437...</td>\n",
       "      <td>[-28.583046, -28.583046, -31.909725, -28.19704...</td>\n",
       "      <td>010355ab</td>\n",
       "      <td>39.9784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 band_1  \\\n",
       "1309  [-26.907173, -27.247885, -25.379496, -25.37954...   \n",
       "730   [-15.341173, -14.21162, -15.837792, -15.923442...   \n",
       "1147  [-20.174095, -20.66132, -21.917173, -21.917212...   \n",
       "896   [-29.086002, -29.490072, -24.570494, -24.11330...   \n",
       "829   [-25.889074, -25.889074, -25.604317, -25.60437...   \n",
       "\n",
       "                                                 band_2        id  inc_angle  \\\n",
       "1309  [-29.186039, -27.972126, -28.358276, -28.76238...  004300e6    42.5591   \n",
       "730   [-22.030249, -20.892223, -21.046036, -24.18857...  00e759b3     0.0000   \n",
       "1147  [-27.022549, -25.438961, -21.002024, -21.72630...  00f3862a    45.2814   \n",
       "896   [-23.67878, -24.338787, -29.490143, -29.490211...  00f7ef1c    34.4748   \n",
       "829   [-28.583046, -28.583046, -31.909725, -28.19704...  010355ab    39.9784   \n",
       "\n",
       "      is_iceberg  \n",
       "1309           1  \n",
       "730            0  \n",
       "1147           1  \n",
       "896            1  \n",
       "829            1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.sort('id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20497918107697513"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(train_final.sort('id')['is_iceberg'],np.mean([concat_sub['is_iceberg'],submission_2.sort('id')['is_iceberg']],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1309    1\n",
       "730     0\n",
       "1147    1\n",
       "896     1\n",
       "829     1\n",
       "107     0\n",
       "848     0\n",
       "636     0\n",
       "1509    0\n",
       "1199    0\n",
       "246     1\n",
       "1067    0\n",
       "1565    0\n",
       "1166    0\n",
       "1179    1\n",
       "1057    0\n",
       "1060    1\n",
       "1575    0\n",
       "1162    0\n",
       "508     0\n",
       "1318    0\n",
       "1405    0\n",
       "1368    0\n",
       "1382    0\n",
       "1350    0\n",
       "640     0\n",
       "80      0\n",
       "1453    0\n",
       "1492    1\n",
       "945     0\n",
       "       ..\n",
       "1134    0\n",
       "1297    1\n",
       "740     0\n",
       "1117    0\n",
       "145     0\n",
       "1538    0\n",
       "761     1\n",
       "728     1\n",
       "1176    0\n",
       "101     0\n",
       "362     0\n",
       "890     1\n",
       "499     0\n",
       "28      1\n",
       "133     1\n",
       "1076    1\n",
       "887     0\n",
       "643     1\n",
       "756     1\n",
       "1275    0\n",
       "613     1\n",
       "684     0\n",
       "205     0\n",
       "525     1\n",
       "734     1\n",
       "1363    1\n",
       "1047    0\n",
       "1251    0\n",
       "787     1\n",
       "886     1\n",
       "Name: is_iceberg, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
